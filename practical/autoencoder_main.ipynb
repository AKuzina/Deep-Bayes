{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, inp_size, hid_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \"\"\"\n",
    "        Here you should define layers of your autoencoder\n",
    "        Please note, if a layer has trainable parameters, it should be nn.Linear. \n",
    "        ## !! CONVOLUTIONAL LAYERS CAN NOT BE HERE !! ##\n",
    "        However, you can use any noise inducing layers, e.g. Dropout.\n",
    "\n",
    "        Your network must not have more than six layers with trainable parameters.\n",
    "        :param inp_size: integer, dimension of the input object\n",
    "        :param hid_size: integer, dimension of the hidden representation\n",
    "        \"\"\"\n",
    "   \n",
    "        self.fc1 = nn.Linear(inp_size, ((inp_size + hid_size)*2)//3)\n",
    "        self.fc2 = nn.Linear(((inp_size + hid_size)*2)//3, (inp_size + hid_size)//3)\n",
    "        self.fc3 = nn.Linear((inp_size + hid_size)//3, hid_size)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hid_size, (inp_size + hid_size)//3)\n",
    "        self.fc5 = nn.Linear((inp_size + hid_size)//3, ((inp_size + hid_size)*2)//3)\n",
    "        self.fc6 = nn.Linear(((inp_size + hid_size)*2)//3, inp_size)\n",
    "        \n",
    "        self.drop = nn.Dropout()\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes objects to hidden representations (E: R^inp_size -> R^hid_size)\n",
    "\n",
    "        :param x: inputs, Variable of shape (batch_size, inp_size)\n",
    "        :return:  hidden represenation of the objects, Variable of shape (batch_size, hid_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.drop(nn.functional.relu(self.fc1(x)))\n",
    "        x = self.drop(nn.functional.relu(self.fc2(x)))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, h):\n",
    "        \"\"\"\n",
    "        Decodes objects from hidden representations (D: R^hid_size -> R^inp_size)\n",
    "\n",
    "        :param h: hidden represenatations, Variable of shape (batch_size, hid_size)\n",
    "        :return:  reconstructed objects, Variable of shape (batch_size, inp_size)\n",
    "        \"\"\"\n",
    "        x = self.drop(nn.functional.relu(self.fc4(h)))\n",
    "        x = self.drop(nn.functional.relu(self.fc5(x)))\n",
    "        x = nn.functional.relu(self.fc6(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Encodes inputs to hidden representations and decodes back.\n",
    "\n",
    "        x: inputs, Variable of shape (batch_size, inp_size)\n",
    "        return: reconstructed objects, Variable of shape (batch_size, inp_size)\n",
    "        \"\"\"\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def loss_function(self, recon_x, x, lam = 1e-4):\n",
    "        \"\"\"\n",
    "        Calculates the loss function.\n",
    "\n",
    "        :params recon_x: reconstructed object, Variable of shape (batch_size, inp_size)\n",
    "        :params x: original object, Variable of shape (batch_size, inp_size)\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        l1_crit = nn.L1Loss(size_average=False)\n",
    "        l1_reg = 0\n",
    "        for param in self.parameters():\n",
    "            l1_reg += l1_crit(param, target=torch.zeros_like(param))\n",
    "\n",
    "        return torch.sum(torch.pow(recon_x - x,2)) / recon_x.shape[0] + lam * l1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, test_loader, n_ep = 10):\n",
    "    for epoch in range(n_ep):\n",
    "        model.train()\n",
    "        train_loss, test_loss = 0, 0\n",
    "        for data, _ in train_loader:\n",
    "            data = Variable(data).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            loss = model.loss_function(x_rec, data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data[0]\n",
    "        print('=> Epoch: %s Average loss: %.3f' % (epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "        model.eval()\n",
    "        for data, _ in test_loader:\n",
    "            data = Variable(data, volatile=True).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            test_loss += model.loss_function(x_rec, data).data[0]\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('=> Test set loss: %.3f' % test_loss)\n",
    "\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data.view(-1, 1, 28, 28)[:n], x_rec.view(-1, 1, 28, 28)[:n]])\n",
    "        if not os.path.exists('./pics'): os.makedirs('./pics')\n",
    "        save_image(comparison.data.cpu(), 'pics/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_work():\n",
    "    print('Start test')\n",
    "    get_loader = lambda train: torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=train, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=50, shuffle=True)\n",
    "    train_loader, test_loader = get_loader(True), get_loader(False)\n",
    "    \n",
    "    try:\n",
    "        model = AutoEncoder(inp_size=784, hid_size=20)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    except Exception:\n",
    "        assert False, 'Error during model creation'\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        model = train(model, optimizer, train_loader, test_loader)\n",
    "    except Exception:\n",
    "        assert False, 'Error during training'\n",
    "        return\n",
    "\n",
    "    test_x = Variable(torch.randn(1, 784))    \n",
    "    rec_x, hid_x = model(test_x), model.encode(test_x)\n",
    "    submodules = dict(model.named_children())\n",
    "    layers_with_params = np.unique(['.'.join(n.split('.')[:-1]) for n, _ in model.named_parameters()])\n",
    "    \n",
    "    assert (hid_x.dim() == 2) and (hid_x.size(1) == 20),  'Hidden representation size must be equal to 20'\n",
    "    assert (rec_x.dim() == 2) and (rec_x.size(1) == 784), 'Reconstruction size must be equal to 784'\n",
    "    assert len(layers_with_params) <= 6, 'The model must have no more than 6 layers '\n",
    "    assert np.all(np.concatenate([list(p.shape) for p in model.parameters()]) <= 800), 'All hidden sizes must be less than 800'\n",
    "    assert np.all([isinstance(submodules[name], nn.Linear) for name in layers_with_params]), 'All layers with parameters must be nn.Linear'\n",
    "    print('Success!ðŸŽ‰')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "=> Epoch: 0 Average loss: 0.737\n",
      "=> Test set loss: 0.541\n",
      "=> Epoch: 1 Average loss: 0.615\n",
      "=> Test set loss: 0.493\n",
      "=> Epoch: 2 Average loss: 0.590\n",
      "=> Test set loss: 0.471\n",
      "=> Epoch: 3 Average loss: 0.581\n",
      "=> Test set loss: 0.456\n",
      "=> Epoch: 4 Average loss: 0.574\n",
      "=> Test set loss: 0.451\n",
      "=> Epoch: 5 Average loss: 0.569\n",
      "=> Test set loss: 0.445\n",
      "=> Epoch: 6 Average loss: 0.565\n",
      "=> Test set loss: 0.436\n",
      "=> Epoch: 7 Average loss: 0.562\n",
      "=> Test set loss: 0.433\n",
      "=> Epoch: 8 Average loss: 0.559\n",
      "=> Test set loss: 0.436\n",
      "=> Epoch: 9 Average loss: 0.557\n",
      "=> Test set loss: 0.429\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method AutoEncoder.encode of AutoEncoder(\n",
       "  (fc1): Linear(in_features=784, out_features=536, bias=True)\n",
       "  (fc2): Linear(in_features=536, out_features=268, bias=True)\n",
       "  (fc3): Linear(in_features=268, out_features=20, bias=True)\n",
       "  (fc4): Linear(in_features=20, out_features=268, bias=True)\n",
       "  (fc5): Linear(in_features=268, out_features=536, bias=True)\n",
       "  (fc6): Linear(in_features=536, out_features=784, bias=True)\n",
       "  (drop): Dropout(p=0.5)\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder(inp_size=784, hid_size=20)\n",
    "model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
